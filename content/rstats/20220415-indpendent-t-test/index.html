---
title: "Independent sample t-test"
authors:
- admin
date: 2022-04-14T21:13:14-05:00
output:
  html_document:
    highlight: textmate
categories: ["R"]
subtitle: ""
summary: The independent *t* test is used for testing the difference between means of two independent groups. It is particularly useful when the research question requires the comparison of variables (measured at least at the ordinal level) obtained from two independent samples.
tags: ["t-test", "parametric", "compare means"]
---



<p><br></p>
<p><img src="/notes/20220415-indpendent-t-test/20220416-t-tests_files/para_non_parametric_tests.jpg"/></p>
<p><br></p>
<div id="aim" class="section level1">
<h1>Aim</h1>
<p>The independent <em>t</em> test is used for testing the difference between means of two independent groups. It is particularly useful when the research question requires the comparison of variables (measured at least at the ordinal level) obtained from two independent samples.</p>
<p><br></p>
</div>
<div id="assumptions" class="section level1">
<h1>Assumptions</h1>
<ul>
<li><p>Independence - the two groups are independent of one another.</p></li>
<li><p>Normality - the dependent variable is normally distributed.</p></li>
<li><p>Homogeneity of variance - the distribution of the dependent variable for one of the groups being compared has the same variance as the distribution for the other group being compared.</p></li>
</ul>
<p><br></p>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<pre class="r"><code>skimr::skim_tee(memory_ability)</code></pre>
<pre><code>── Data Summary ────────────────────────
                           Values
Name                       data  
Number of rows             20    
Number of columns          2     
_______________________          
Column type frequency:           
  factor                   1     
  numeric                  1     
________________________         
Group variables            None  

── Variable type: factor ───────────────────────────────────────────────────────
  skim_variable n_missing complete_rate ordered n_unique top_counts      
1 gender                0             1 FALSE          2 Mal: 10, Fem: 10

── Variable type: numeric ──────────────────────────────────────────────────────
  skim_variable n_missing complete_rate mean   sd p0 p25  p50  p75 p100 hist 
1 words                 0             1 19.9 3.89 14  17 19.5 23.2   26 ▆▇▆▃▇</code></pre>
<p><br></p>
</div>
<div id="testing-assumptions" class="section level1">
<h1>Testing assumptions</h1>
<div id="independence" class="section level2">
<h2>Independence</h2>
<p>During data collection, ensure that the observation in one group are independent of the observations of the other group.</p>
<p><br></p>
</div>
<div id="normality-test" class="section level2">
<h2>Normality test</h2>
<p>For a start, a qqplot or the “quantile-quantile” plot can be used to quickly assess whether or not the data or a variable follows a normal distribution. If normally distributed, the data points will lie on the straight diagonal line. For the qqplot below, most of the points lie on the diagonal line but with some deviations along each of the tails.</p>
<pre class="r"><code>qqnorm(memory_ability$words)
qqline(memory_ability$words)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Whereas the Shapiro-Wilk statistic tests for normality. If the significance level are greater than 0.05, then normality is assumed. The Shapiro-Wilk test is recommended when sample size is small (~ &lt;50). Result of the Shapiro-Wilk test below, the computed significance level is 0.201, implying normality can be assumed.</p>
<pre class="r"><code>shapiro.test(memory_ability$words)</code></pre>
<pre><code>
    Shapiro-Wilk normality test

data:  memory_ability$words
W = 0.93591, p-value = 0.2005</code></pre>
<p><br></p>
</div>
<div id="homogeneity-of-variance" class="section level2">
<h2>Homogeneity of variance</h2>
<p>The Levene’s test can be used to check the assumption on the homogeneity of variance. The Levene’s tes for equality of variance tests the hypothesis that the two population variances are equal.</p>
<p>The results below shows that the Levene statistic is <em>F=0.087</em> and the corresponding level of significance is large (i.e., <em>p&gt;0.05</em>). Hence, the assumption of homogeneity of variance has not been violated, and the equal variances assumed implying <em>t</em> test statistic can be used for evaluating the null hypothesis of equality of means.</p>
<pre class="r"><code>car::leveneTest(words ~ gender, data = memory_ability, center = &quot;mean&quot;)</code></pre>
<pre><code>Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;)
      Df F value Pr(&gt;F)
group  1  0.0869 0.7715
      18               </code></pre>
<p><br></p>
</div>
</div>
<div id="results-and-interpretation" class="section level1">
<h1>Results and interpretation</h1>
<p>The result from the <em>t</em> test indicate that there is a significant differenc between the male and female samples in the number of words correctly recalled, <em>t(df=18)=-3.02, p&lt;0.01</em>. The mean values indicate that females correctly recalled significantly more words (M=22.10) than males(M=17.70).</p>
<p>The confidence interval information shows that the null hypothesis value (i.e., zero) does not fall within the interval. Therefore the null hypothesis of equality of means can be rejected.</p>
<pre class="r"><code>ind_ttest &lt;- 
t.test(words ~ gender, data = memory_ability, alternative = &quot;two.sided&quot;)

ind_ttest</code></pre>
<pre><code>
    Welch Two Sample t-test

data:  words by gender
t = -3.0203, df = 17.958, p-value = 0.007367
alternative hypothesis: true difference in means between group Male and group Female is not equal to 0
95 percent confidence interval:
 -7.461101 -1.338899
sample estimates:
  mean in group Male mean in group Female 
                17.7                 22.1 </code></pre>
<p>We can also compute for the eta-square (<span class="math inline">\(\eta^2\)</span>) which can be interpreted in exactly the same as <span class="math inline">\(R^2\)</span> in correlation and regression. That is, approximately 33.63% of the variability in the number of words correctly recalled was explained by the gender manipulation. Eta-square can be calculated by:</p>
<p><span class="math display">\[\eta^2 = \frac{t^2}{t^2 + df}\]</span></p>
<pre class="r"><code>ind_ttest$statistic^2 / (ind_ttest$statistic^2 + ind_ttest$parameter)</code></pre>
<pre><code>        t 
0.3368622 </code></pre>
<p><br></p>
</div>
<div id="manual-computation" class="section level1">
<h1>Manual computation</h1>
<p>The t statistic for the t test for independent sample is given by:</p>
<p><span class="math display">\[
t = \frac{\bar{X_1} - \bar{X_2}}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_1}}}
\]</span></p>
<p>where <span class="math inline">\(\bar{X}\)</span> is the mean value for each group, <span class="math inline">\(S^2\)</span> is the sample variance, and <span class="math inline">\(n\)</span> number of observation in each group.</p>
<pre class="r"><code># X1 - mean words recalled by male
mean_male &lt;- 
memory_ability %&gt;% filter(gender == &quot;Male&quot;) %&gt;% summarise(m_words = mean(words)) %&gt;% pull()

# X2 - mean words recalled by female
mean_female &lt;- 
memory_ability %&gt;% filter(gender == &quot;Female&quot;) %&gt;% summarise(m_words = mean(words)) %&gt;% pull()

# s1 - variance of words recalled by male
variance_male &lt;- 
memory_ability %&gt;% filter(gender == &quot;Male&quot;) %&gt;% summarise(m_words = var(words)) %&gt;% pull()

# s2 - variance of words recalled by female
variance_female &lt;- 
memory_ability %&gt;% filter(gender == &quot;Female&quot;) %&gt;% summarise(m_words = var(words)) %&gt;% pull()

# no of male
n_male &lt;- 
memory_ability %&gt;% filter(gender == &quot;Male&quot;) %&gt;% count() %&gt;% pull()

# no of female
n_female &lt;- 
memory_ability %&gt;% filter(gender == &quot;Female&quot;) %&gt;% count() %&gt;% pull()</code></pre>
<pre class="r"><code># Computing the t statistic
t_stat &lt;- 
(mean_male - mean_female) / sqrt((variance_male/n_male) + (variance_female/ n_female))

t_stat</code></pre>
<pre><code>[1] -3.02035</code></pre>
<pre class="r"><code># Deriving the two-tailed p-value
pt(q = t_stat, df = 18) * 2</code></pre>
<pre><code>[1] 0.007352521</code></pre>
<p><br></p>
<hr />
<div id="references" class="section level2">
<h2>References</h2>
<p>Ho, Robert (2014).Handbook of Univariate and Multivariate Data Analysis with IBM SPSS (2nd edition). Chapman &amp; Hall/CRC, Taylor &amp; Francis Group.</p>
<p>Sheskin, David J. (2011). Handbook of Parametric and Nonparametric Statistical Procedures (5th edition). Chapman &amp; Hall/CRC, Taylor &amp; Francis Group.</p>
</div>
</div>
